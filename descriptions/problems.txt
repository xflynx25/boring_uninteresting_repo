October: self-created features like days_rest & transfers_balance failing
November: Ramsdale/Areola scoring outrageously high 
    Sol: May need to use some ranking features amongst the other keepers, to nerf him
December: 1) AVL & NEW have blank week but getting put as top scorers
    Sol: most trees don't even grab FIX1 num_opponents, and actually may 
        grab the other features that are also zero, implying opponent is bad
    Fix: Manually check for no game in gameweek? Yes this is ok because it 
        causes all the data to be bad for that unit. Therefore we should remove
        in the training set as well. 
    2) transfers_balance still high importance on many models...perhaps bad feature, 
        worried it's causing weird predictions for low ownership players
    Sol: Seems to be pretty accurate, maybe we can use this to solve....nextline
    Fix: Switch feature to a ranking over all the players, percentage wise. 
        or 1-hot over certain thresholds
    3) Injured players take a while to transfer out 
    Fix: use transfers_balance combined with health to determine if injured 
    
right now, we should run 1-hot goalkeeper and see if good enough to wildcard, 
next week fix the three things above --> 
get a clean methodology for chips that is REDUNDANT
then clean up all the files and upload to git (include cleaning imports deleting unnecessary funcs)
Make a visual.py for seeing what is going on, easy toggle on/off
then work on adding a few more manual features / try neural net / try no-price
customize when in week to transfer (logic)
write api documentation (by the 20th)


February: For computation saving the statistics are computed only once...this could be a problem 
    for automation of when in week to make transfer...if they are sharing a .csv then a team
    late in the week isn't actually getting the increased information from waiting.
    *Keepers evaluation is rather high
    *implant typical human chip strategies - wildcard before dgw
    *in double gameweek later odds sometimes don't come out, right now are just making all 3 
        but should make it more respective of team strength

    *** The chips are not actually played by amosbastian front-end ,, we will need to either 
    debug this manually or go with fallback solution of emailing people or something...
    unsatisfying because wouldn't be completely autonomous and require some checking of the human supervisor. :(

April:
    Keepers are still not doing well. Transferring in de gea when only played 6 games ago. Bringing in and
    captaining darlow yet hasn't played in 10 games and is injured. 
    Keeping the faith in salah so long with the armband?
    Reverse engineering playing chips automatically would be HUGE, cost me big points when i didn't check my junk email. 

May:
    We have found a HUGE bug. For some reason in player raw the gw18 stats are added after the last played gw.
    This is causing the L1 statistics to reference the gw18 statistics, for everyone except liverpool who
    did not have a gw 18. We think a good place to start hunting this is in Accountant2helpers last_games_stats(df, n) function,
    where I wrote some especially sketchy code. 
    ,/* gw 18 is repeating, and we read off last 6 gw as 37 ,18, 36, 18, 35, 18
    * also, for those who don't play like that, we read off L3 as 37, 36, 35, 35 (so their averages look huge)
    ,/* day 396 for salah ... that don't make sense
    * Not have games played in the stats? 

    * so we first need to get rid of the repetat 18 that is being inserted, then we need to make sure that all the features
    are actually makin git into the tables (num_games), and then we decide
    if we still agree with the design decision to sum up all the games in L6 gameweeks, 
    or make the statistic for just last 6 games. I'm right now leaning to doing it as is, but we should
    make the divisor not 6 but the number of games so that it is not misleading when 
    there is double gameweeks. Although the other way around is misleading too. That is why this 
    is a difficult design decision. How to give the computer adequate information to understand what is going on here within the 
    context of the modeling framework we are training it in? 

    The questoin is, in dgw - good players are more likely to be benched, 
    and their scores will go down. How to account for not valuing players 
    who just had dgw worse than ones that didn't. 

    1) nan was_home during tgw
    2) Clearly just summing values when they are put into raw_players, we are recording by gw...not game. --| The error is not in raw_player_gw
    3) this is also resulting in people having big weeks calculated for them when really it was spread over 2. 
    **even when we correct temporarily by just putting the averages into each gw, this isn't a great long term solution
    ****ideally, we would prefer last 6 games rather than played gws. So it would theoretically stretch over the same period of relevance.
    ******The other option is to keep it this way and include how many games have been played. 
    LOOKS LIKE WE FIXED THIS ALL 
